{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network analysis on segment level\n",
    "\n",
    "Split up the segments into groups of segment type and solar exposure class. Use the resulting files to find critical and favorable segments in the road network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ignore FutureWarnings from geopandas\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', message='.*initial implementation of Parquet.*')\n",
    "# Ignore SettingWithCopyWarning from (geo-)pandas\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# Config\n",
    "tod_list = ['10am', '1pm', '4pm', '7pm']\n",
    "\n",
    "day = 170\n",
    "sensitivity_factor = 1.0\n",
    "\n",
    "in_dir = Path(f'../../export/{day}/{sensitivity_factor}/exportdata/aggregation')\n",
    "out_dir = in_dir.parent.parent / 'analysis'\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "out_segment_level = out_dir / 'segment_level'\n",
    "out_segment_level.mkdir(exist_ok=True)\n",
    "\n",
    "default_type = 'shortest'\n",
    "count_threshold = 0.01\n",
    "\n",
    "high_sol_expo = 90\n",
    "low_sol_expo = 50\n",
    "\n",
    "crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def subfolder(out_dir, time_of_day):\n",
    "    \"\"\"Returns the respective folder path and creates subfolders in out_dir with timestamps if not existent already\"\"\"\n",
    "    out_folder = out_dir / f'{time_of_day}'\n",
    "    out_folder.mkdir(exist_ok=True)\n",
    "    return out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters to extract segments ranks \n",
    "class EqualSegmentRanking:\n",
    "    \"\"\"Filters for equal segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, time_of_day):\n",
    "        self.data = data.to_crs(crs)\n",
    "        self.time_of_day = time_of_day\n",
    "\n",
    "    @property\n",
    "    def cool_corridors(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_unavoidables(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, {high_sol_expo} % >= solar exposure']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_unavoidables(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "class DetourSegmentRanking:\n",
    "    \"\"\"Filters for detour segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, time_of_day):\n",
    "        self.data = data.to_crs(crs)\n",
    "        self.time_of_day = time_of_day\n",
    "\n",
    "    @property\n",
    "    def cool_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, {high_sol_expo} % >= solar exposure']\n",
    "            \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "            \n",
    "        return filtered\n",
    "    \n",
    "class DefaultSegmentRanking:\n",
    "    \"\"\"Filters the default segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, equal_segments, time_of_day):\n",
    "        self.time_of_day = time_of_day\n",
    "        # Avoided default segments\n",
    "        self.difference = gpd.overlay(data, equal_segments, how='difference')\n",
    "\n",
    "    @property\n",
    "    def lse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, {high_sol_expo} % >= solar exposure']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "        \n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data of default routes\n",
    "default_file = gpd.read_feather(in_dir / f'counts_{default_type}_alltimes.feather')\n",
    "default_file.to_crs(crs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Read and split up segment data of the optimized routes\n",
    "for time_of_day in tod_list:\n",
    "    print(f'Processing {time_of_day}...')\n",
    "    print(f'...equals...')\n",
    "    equal_segments = EqualSegmentRanking(gpd.read_feather(in_dir / f'counts_{time_of_day}_equal.feather'), time_of_day)\n",
    "\n",
    "    # Equal + low solar exposure\n",
    "    lse_equals = equal_segments.cool_corridors\n",
    "    lse_equals.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_cool_corridors.feather')\n",
    "\n",
    "    # Equal + high solar exposure\n",
    "    hse_unavoidables = equal_segments.hse_unavoidables\n",
    "    hse_unavoidables.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_unavoidables.feather')\n",
    "    \n",
    "    # Equal + medium solar exposure\n",
    "    mse_unavoidables = equal_segments.mse_unavoidables\n",
    "    mse_unavoidables.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_unavoidables.feather')\n",
    "\n",
    "    print(f'...detours...')\n",
    "    detour_segments = DetourSegmentRanking(gpd.read_feather(in_dir / f'counts_{time_of_day}_detour.feather'), time_of_day)\n",
    "\n",
    "    # Detour + low solar exposure\n",
    "    lse_detours = detour_segments.cool_detours\n",
    "    lse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_cool_detours.feather')\n",
    "\n",
    "    # Detour + high solar exposure\n",
    "    hse_detours = detour_segments.hse_detours\n",
    "    hse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_detours.feather')\n",
    "\n",
    "    # Detour + medium solar exposure\n",
    "    mse_detours = detour_segments.mse_detours\n",
    "    mse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_detours.feather')\n",
    "    \n",
    "    print(f'...avoided segments...')\n",
    "    default_segments = DefaultSegmentRanking(default_file, equal_segments.data, time_of_day)\n",
    "\n",
    "    # Avoided + low solar exposure\n",
    "    lse_avoided = default_segments.lse_defaults\n",
    "    lse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_lse_avoided.feather')\n",
    "    # Avoided + high solar exposure\n",
    "    hse_avoided = default_segments.hse_defaults\n",
    "    hse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_avoided.feather')\n",
    "    # Avoided + medium solar exposure\n",
    "    mse_avoided = default_segments.mse_defaults\n",
    "    mse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_avoided.feather')\n",
    "\n",
    "    avoided = pd.concat([lse_avoided, hse_avoided, mse_avoided], ignore_index=True)\n",
    "    avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_avoided.feather')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Solar-Exposure (HSE) and Low-Solar-Expsoure (LSE) analysis\n",
    "\n",
    "Find segments that have high or low solar exposure, regardless if they are shortest or detour segments. This helps in understanding the road network towards critical (HSE) or favorable (LSE) segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for handling multi-time segment data\n",
    "def merge_segments(dict):\n",
    "    \"\"\"Finds segments of similar solar exposure class\"\"\"\n",
    "    segdata = None\n",
    "\n",
    "    for gdf in dict.values():\n",
    "        if segdata is None:\n",
    "            segdata = gdf\n",
    "        else:\n",
    "            segdata = gpd.overlay(segdata, gdf, how='intersection')\n",
    "            segdata = segdata.loc[:, ~segdata.columns.str.endswith('_1')]\n",
    "            segdata = segdata.loc[:, ~segdata.columns.str.endswith('_2')]\n",
    "\n",
    "    return segdata.reset_index(drop=True)\n",
    "\n",
    "def merge_rest(dict):\n",
    "    \"\"\"Merges the remaining segments\"\"\"\n",
    "    return pd.concat(dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSE segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hse_dict = {}\n",
    "mse_dict = {}\n",
    "rest_dict = {}\n",
    "\n",
    "for tod in tod_list[1:3]:  # slice here to select times of day\n",
    "    hse_unavoidables = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_unavoidables.feather')\n",
    "    hse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_detours.feather')\n",
    "    hse_dict[f'{tod}_hse'] = hse_unavoidables.append(hse_detours)\n",
    "\n",
    "    mse_unavoidables = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_unavoidables.feather')\n",
    "    mse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_detours.feather')    \n",
    "    lse_equals = gpd.read_feather(out_segment_level / tod / f'{tod}_cool_corridors.feather')\n",
    "    lse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_cool_detours.feather')\n",
    "    avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_avoided.feather')\n",
    "    rest_dict[f'{tod}_rest'] = avoided.append(lse_equals).append(lse_detours).append(mse_unavoidables).append(mse_detours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hse = merge_segments(hse_dict)\n",
    "rest = merge_segments(rest_dict)\n",
    "\n",
    "hse_critical = hse.overlay(rest, how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hse_critical.to_feather(out_seg_filter_rank / 'hse_critical.feather')\n",
    "hse_critical.to_feather(out_segment_level / 'hse_critical_1-4.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSE segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lse_dict = {}\n",
    "rest_dict = {}\n",
    "\n",
    "for tod in tod_list[1:3]:  # slice here to select times of day\n",
    "    lse_equals = gpd.read_feather(out_segment_level / tod / f'{tod}_cool_corridors.feather')\n",
    "    lse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_cool_detours.feather')\n",
    "    lse_dict[f'{tod}'] = lse_equals.append(lse_detours)\n",
    "\n",
    "    avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_avoided.feather')\n",
    "    hse_unavoidables = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_unavoidables.feather')\n",
    "    hse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_detours.feather')\n",
    "    mse_unavoidables = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_unavoidables.feather')\n",
    "    mse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_detours.feather')   \n",
    "    rest_dict[f'{tod}'] = avoided.append(hse_unavoidables).append(hse_detours).append(mse_unavoidables).append(mse_detours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lse = merge_segments(lse_dict)\n",
    "rest = merge_segments(rest_dict)\n",
    "\n",
    "lse_favorable = hse.overlay(rest, how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lse_favorable.to_feather(out_seg_filter_rank / 'lse_favorable.feather')\n",
    "lse_favorable.to_feather(out_segment_level / 'lse_favorable_1-4.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heal-routing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
