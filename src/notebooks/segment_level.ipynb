{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network analysis on segment level\n",
    "\n",
    "Split up the segments into groups of segment type and solar exposure class. Use the resulting files to find critical and favorable segments in the road network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "\n",
    "# Ignore FutureWarnings from geopandas\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', message='.*initial implementation of Parquet.*')\n",
    "# Ignore SettingWithCopyWarning from (geo-)pandas\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# Config\n",
    "tod_list = ['10am', '1pm', '4pm', '7pm']\n",
    "\n",
    "day = 170\n",
    "sensitivity_factor = 1.0\n",
    "\n",
    "in_dir = Path(f'../../export/{day}/{sensitivity_factor}/exportdata/aggregation')\n",
    "out_dir = in_dir.parent.parent / 'analysis'\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "out_segment_level = out_dir / 'segment_level'\n",
    "out_segment_level.mkdir(exist_ok=True)\n",
    "\n",
    "default_type = 'shortest'\n",
    "count_threshold = 0.01\n",
    "\n",
    "high_sol_expo = 90\n",
    "low_sol_expo = 50\n",
    "\n",
    "crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def subfolder(out_dir, time_of_day):\n",
    "    \"\"\"Returns the respective folder path and creates subfolders in out_dir with timestamps if not existent already\"\"\"\n",
    "    out_folder = out_dir / f'{time_of_day}'\n",
    "    out_folder.mkdir(exist_ok=True)\n",
    "    return out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters to extract segments ranks \n",
    "class EqualSegmentRanking:\n",
    "    \"\"\"Filters for equal segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, time_of_day):\n",
    "        self.data = data.to_crs(crs)\n",
    "        self.time_of_day = time_of_day\n",
    "\n",
    "    @property\n",
    "    def lse_not_avoided(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_not_avoided(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, {high_sol_expo} % >= solar exposure']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_not_avoided(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "class DetourSegmentRanking:\n",
    "    \"\"\"Filters for detour segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, time_of_day):\n",
    "        self.data = data.to_crs(crs)\n",
    "        self.time_of_day = time_of_day\n",
    "\n",
    "    @property\n",
    "    def lse_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, {high_sol_expo} % >= solar exposure']\n",
    "            \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "            \n",
    "        return filtered\n",
    "    \n",
    "class DefaultSegmentRanking:\n",
    "    \"\"\"Filters the default segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, equal_segments, time_of_day):\n",
    "        self.time_of_day = time_of_day\n",
    "        # Avoided default segments\n",
    "        self.difference = gpd.overlay(data, equal_segments, how='difference')\n",
    "\n",
    "    @property\n",
    "    def lse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, {high_sol_expo} % >= solar exposure']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "        \n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data of default routes\n",
    "default_file = gpd.read_feather(in_dir / f'counts_{default_type}_alltimes.feather')\n",
    "default_file.to_crs(crs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Read and split up segment data of the optimized routes\n",
    "for time_of_day in tod_list:\n",
    "    print(f'Processing {time_of_day}...')\n",
    "    print(f'...equals...')\n",
    "    equal_segments = EqualSegmentRanking(gpd.read_feather(in_dir / f'counts_{time_of_day}_equal.feather'), time_of_day)\n",
    "\n",
    "    # Equal + low solar exposure\n",
    "    lse_not_avoided = equal_segments.lse_not_avoided\n",
    "    lse_not_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_lse_not_avoided.feather')\n",
    "\n",
    "    # Equal + high solar exposure\n",
    "    hse_not_avoided = equal_segments.hse_not_avoided\n",
    "    hse_not_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_not_avoided.feather')\n",
    "    \n",
    "    # Equal + medium solar exposure\n",
    "    mse_not_avoided = equal_segments.mse_not_avoided\n",
    "    mse_not_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_not_avoided.feather')\n",
    "\n",
    "    print(f'...detours...')\n",
    "    detour_segments = DetourSegmentRanking(gpd.read_feather(in_dir / f'counts_{time_of_day}_detour.feather'), time_of_day)\n",
    "\n",
    "    # Detour + low solar exposure\n",
    "    lse_detours = detour_segments.lse_detours\n",
    "    lse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_lse_detours.feather')\n",
    "\n",
    "    # Detour + high solar exposure\n",
    "    hse_detours = detour_segments.hse_detours\n",
    "    hse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_detours.feather')\n",
    "\n",
    "    # Detour + medium solar exposure\n",
    "    mse_detours = detour_segments.mse_detours\n",
    "    mse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_detours.feather')\n",
    "    \n",
    "    print(f'...avoided segments...')\n",
    "    default_segments = DefaultSegmentRanking(default_file, equal_segments.data, time_of_day)\n",
    "\n",
    "    # Avoided + low solar exposure\n",
    "    lse_avoided = default_segments.lse_defaults\n",
    "    lse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_lse_avoided.feather')\n",
    "    # Avoided + high solar exposure\n",
    "    hse_avoided = default_segments.hse_defaults\n",
    "    hse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_avoided.feather')\n",
    "    # Avoided + medium solar exposure\n",
    "    mse_avoided = default_segments.mse_defaults\n",
    "    mse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_avoided.feather')\n",
    "\n",
    "    avoided = pd.concat([lse_avoided, hse_avoided, mse_avoided], ignore_index=True)\n",
    "    avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_avoided.feather')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Case Analysis\n",
    "\n",
    "Find segments that have high or low solar exposure, regardless if they are shortest or detour segments. This helps in understanding the road network towards critical or favorable segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_segments(gdfs_dict):\n",
    "    \"\"\"Finds segments of similar solar exposure class\"\"\"\n",
    "    segdata = None\n",
    "    count_col = 'count_relative'\n",
    "\n",
    "    for gdf in gdfs_dict.values():\n",
    "        if segdata is None:\n",
    "            segdata = gdf\n",
    "            segdata[f'{count_col}_sum'] = segdata[count_col]\n",
    "        else:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\", message=\"`keep_geom_type=True`\")\n",
    "                segdata = gpd.overlay(segdata, gdf, how='intersection')\n",
    "            segdata[f'{count_col}_sum'] = segdata[f'{count_col}_sum'] + segdata.get(f'{count_col}_2', segdata.get(count_col, 0))\n",
    "            segdata = segdata.loc[:, ~segdata.columns.str.endswith('_1')]\n",
    "            segdata = segdata.loc[:, ~segdata.columns.str.endswith('_2')]\n",
    "\n",
    "    segdata[f'{count_col}_avg'] = segdata[f'{count_col}_sum'] / len(gdfs_dict)\n",
    "    segdata.drop(f'{count_col}_sum', axis=1, inplace=True)\n",
    "    return segdata.reset_index(drop=True)\n",
    "\n",
    "def merge_rest(dict):\n",
    "    \"\"\"Merges the remaining segments\"\"\"\n",
    "    return pd.concat(dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot Corridors\n",
    "\n",
    "These are shortest or detour segments with high solar exposure, critical to the road network and potential candidates for adaptation measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hot_corridors(tod_list, start, end=None):\n",
    "    hcs_dicts = {}\n",
    "    rest_dict = {}\n",
    "\n",
    "    end_index = end - 1 if end is not None else -1\n",
    "    print(f'Finding hot corridors for times of day {tod_list[start]} to {tod_list[end_index]}...')\n",
    "\n",
    "    for tod in islice(tod_list, start, end):\n",
    "        hse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_not_avoided.feather')\n",
    "        hse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_detours.feather')\n",
    "        hcs_dicts[f'{tod}_hse'] = hse_not_avoided.append(hse_detours)\n",
    "\n",
    "        mse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_not_avoided.feather')\n",
    "        mse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_detours.feather')    \n",
    "        lse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_lse_not_avoided.feather')\n",
    "        lse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_lse_detours.feather')\n",
    "        avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_avoided.feather')\n",
    "        rest_dict[f'{tod}_rest'] = avoided.append(lse_not_avoided).append(lse_detours).append(mse_not_avoided).append(mse_detours)\n",
    "    \n",
    "    hc = merge_segments(hcs_dicts)\n",
    "    rest = merge_rest(rest_dict)\n",
    "\n",
    "    hot_corridors = hc.overlay(rest, how='difference')\n",
    "    \n",
    "    if end:\n",
    "        outname = f'hot_corridors_{tod_list[start]}-{tod_list[end-1]}'\n",
    "    else:\n",
    "        outname = f'hot_corridors'\n",
    "    hot_corridors.to_feather(out_segment_level / f'{outname}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding hot corridors for times of day 10am to 7pm...\n",
      "Finding hot corridors for times of day 1pm to 4pm...\n"
     ]
    }
   ],
   "source": [
    "# Hot corridors for all times of day\n",
    "process_hot_corridors(tod_list, 0)\n",
    "# Hot corridors for 1 PM and 4 PM\n",
    "process_hot_corridors(tod_list, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cool Corridors\n",
    "\n",
    "These are shortest segments with low solar exposure, the best case for shade-optimized routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cool_corridors(tod_list, start, end=None):\n",
    "    ccs_dict = {}\n",
    "    rest_dict = {}\n",
    "\n",
    "    end_index = end - 1 if end is not None else -1\n",
    "    print(f'Finding cool corridors for times of day {tod_list[start]} to {tod_list[end_index]}...')\n",
    "\n",
    "    for tod in islice(tod_list, start, end):\n",
    "        lse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_lse_not_avoided.feather')\n",
    "        ccs_dict[f'{tod}'] = lse_not_avoided\n",
    "\n",
    "        avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_avoided.feather')\n",
    "        hse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_not_avoided.feather')\n",
    "        hse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_detours.feather')\n",
    "        mse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_not_avoided.feather')\n",
    "        mse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_detours.feather')   \n",
    "        lse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_lse_detours.feather')\n",
    "        rest_dict[f'{tod}'] = avoided.append(hse_not_avoided).append(hse_detours).append(mse_not_avoided).append(mse_detours).append(lse_detours)\n",
    "    \n",
    "    cc = merge_segments(ccs_dict)\n",
    "    rest = merge_rest(rest_dict)\n",
    "\n",
    "    cool_corridors = cc.overlay(rest, how='difference')\n",
    "    \n",
    "    if end:\n",
    "        outname = f'cool_corridors_{tod_list[start]}-{tod_list[end-1]}'\n",
    "    else:\n",
    "        outname = f'cool_corridors'\n",
    "    cool_corridors.to_feather(out_segment_level / f'{outname}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding cool corridors for times of day 10am to 7pm...\n",
      "Finding cool corridors for times of day 1pm to 4pm...\n"
     ]
    }
   ],
   "source": [
    "# Cool corridors for all times of day\n",
    "process_cool_corridors(tod_list, 0)\n",
    "# Cool corridors for 1 PM and 4 PM\n",
    "process_cool_corridors(tod_list, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Favorable LSE segments\n",
    "\n",
    "These are shortest or detour segments with low solar exposure, favorable when traveling across the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lse_favorable(tod_list, start, end=None):\n",
    "    lse_favs_dict = {}\n",
    "    rest_dict = {}\n",
    "\n",
    "    end_index = end - 1 if end is not None else -1\n",
    "    print(f'Finding favorable LSE segments for times of day {tod_list[start]} to {tod_list[end_index]}...')\n",
    "\n",
    "    for tod in islice(tod_list, start, end):\n",
    "        lse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_lse_not_avoided.feather')\n",
    "        lse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_lse_detours.feather')\n",
    "        lse_favs_dict[f'{tod}'] = lse_not_avoided.append(lse_detours)\n",
    "\n",
    "        avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_avoided.feather')\n",
    "        hse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_not_avoided.feather')\n",
    "        hse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_detours.feather')\n",
    "        mse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_not_avoided.feather')\n",
    "        mse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_detours.feather')   \n",
    "        rest_dict[f'{tod}'] = avoided.append(hse_not_avoided).append(hse_detours).append(mse_not_avoided).append(mse_detours)\n",
    "    \n",
    "    lse_fav = merge_segments(lse_favs_dict)\n",
    "    rest = merge_rest(rest_dict)\n",
    "\n",
    "    lse_favorable = lse_fav.overlay(rest, how='difference')\n",
    "    \n",
    "    if end:\n",
    "        outname = f'lse_favorable_{tod_list[start]}-{tod_list[end-1]}'\n",
    "    else:\n",
    "        outname = f'lse_favorable'\n",
    "    lse_favorable.to_feather(out_segment_level / f'{outname}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding favorable LSE segments for times of day 10am to 7pm...\n",
      "Finding favorable LSE segments for times of day 1pm to 4pm...\n"
     ]
    }
   ],
   "source": [
    "# Favorable LSE segments for all times of day\n",
    "process_lse_favorable(tod_list, 0)\n",
    "# Favorable LSE segments for 1 PM and 4 PM\n",
    "process_lse_favorable(tod_list, 1, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heal-routing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
