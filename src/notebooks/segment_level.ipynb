{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network analysis on segment level\n",
    "\n",
    "Split up the segments into groups of segment type and solar exposure class. Use the resulting files to find critical and favorable segments in the road network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Ignore FutureWarnings from geopandas\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', message='.*initial implementation of Parquet.*')\n",
    "# Ignore SettingWithCopyWarning from (geo-)pandas\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# Config\n",
    "tod_list = ['10am', '1pm', '4pm', '7pm']\n",
    "\n",
    "day = 170\n",
    "sensitivity_factor = 1.0\n",
    "\n",
    "in_dir = Path(f'../../export/{day}/{sensitivity_factor}/exportdata/aggregation')\n",
    "out_dir = in_dir.parent.parent / 'analysis'\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "out_segment_level = out_dir / 'segment_level'\n",
    "out_segment_level.mkdir(exist_ok=True)\n",
    "\n",
    "default_type = 'shortest'\n",
    "count_threshold = 0.01\n",
    "\n",
    "high_sol_expo = 90\n",
    "low_sol_expo = 50\n",
    "\n",
    "crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def subfolder(out_dir, time_of_day):\n",
    "    \"\"\"Returns the respective folder path and creates subfolders in out_dir with timestamps if not existent already\"\"\"\n",
    "    out_folder = out_dir / f'{time_of_day}'\n",
    "    out_folder.mkdir(exist_ok=True)\n",
    "    return out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters to extract segments ranks \n",
    "class EqualSegmentRanking:\n",
    "    \"\"\"Filters for equal segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, time_of_day):\n",
    "        self.data = data.to_crs(crs)\n",
    "        self.time_of_day = time_of_day\n",
    "\n",
    "    @property\n",
    "    def lse_not_avoided(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_not_avoided(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, {high_sol_expo} % >= solar exposure']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_not_avoided(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "class DetourSegmentRanking:\n",
    "    \"\"\"Filters for detour segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, time_of_day):\n",
    "        self.data = data.to_crs(crs)\n",
    "        self.time_of_day = time_of_day\n",
    "\n",
    "    @property\n",
    "    def lse_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, {high_sol_expo} % >= solar exposure']\n",
    "            \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "            \n",
    "        return filtered\n",
    "    \n",
    "class DefaultSegmentRanking:\n",
    "    \"\"\"Filters the default segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, equal_segments, time_of_day):\n",
    "        self.time_of_day = time_of_day\n",
    "        # Avoided default segments\n",
    "        self.difference = gpd.overlay(data, equal_segments, how='difference')\n",
    "\n",
    "    @property\n",
    "    def lse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, {high_sol_expo} % >= solar exposure']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "        \n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data of default routes\n",
    "default_file = gpd.read_feather(in_dir / f'counts_{default_type}_alltimes.feather')\n",
    "default_file.to_crs(crs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Read and split up segment data of the optimized routes\n",
    "for time_of_day in tod_list:\n",
    "    print(f'Processing {time_of_day}...')\n",
    "    print(f'...equals...')\n",
    "    equal_segments = EqualSegmentRanking(gpd.read_feather(in_dir / f'counts_{time_of_day}_equal.feather'), time_of_day)\n",
    "\n",
    "    # Equal + low solar exposure\n",
    "    lse_not_avoided = equal_segments.lse_not_avoided\n",
    "    lse_not_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_lse_not_avoided.feather')\n",
    "\n",
    "    # Equal + high solar exposure\n",
    "    hse_not_avoided = equal_segments.hse_not_avoided\n",
    "    hse_not_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_not_avoided.feather')\n",
    "    \n",
    "    # Equal + medium solar exposure\n",
    "    mse_not_avoided = equal_segments.mse_not_avoided\n",
    "    mse_not_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_not_avoided.feather')\n",
    "\n",
    "    print(f'...detours...')\n",
    "    detour_segments = DetourSegmentRanking(gpd.read_feather(in_dir / f'counts_{time_of_day}_detour.feather'), time_of_day)\n",
    "\n",
    "    # Detour + low solar exposure\n",
    "    lse_detours = detour_segments.lse_detours\n",
    "    lse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_lse_detours.feather')\n",
    "\n",
    "    # Detour + high solar exposure\n",
    "    hse_detours = detour_segments.hse_detours\n",
    "    hse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_detours.feather')\n",
    "\n",
    "    # Detour + medium solar exposure\n",
    "    mse_detours = detour_segments.mse_detours\n",
    "    mse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_detours.feather')\n",
    "    \n",
    "    print(f'...avoided segments...')\n",
    "    default_segments = DefaultSegmentRanking(default_file, equal_segments.data, time_of_day)\n",
    "\n",
    "    # Avoided + low solar exposure\n",
    "    lse_avoided = default_segments.lse_defaults\n",
    "    lse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_lse_avoided.feather')\n",
    "    # Avoided + high solar exposure\n",
    "    hse_avoided = default_segments.hse_defaults\n",
    "    hse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_avoided.feather')\n",
    "    # Avoided + medium solar exposure\n",
    "    mse_avoided = default_segments.mse_defaults\n",
    "    mse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_avoided.feather')\n",
    "\n",
    "    avoided = pd.concat([lse_avoided, hse_avoided, mse_avoided], ignore_index=True)\n",
    "    avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_avoided.feather')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Solar-Exposure (HSE) and Low-Solar-Expsoure (LSE) analysis\n",
    "\n",
    "Find segments that have high or low solar exposure, regardless if they are shortest or detour segments. This helps in understanding the road network towards critical (HSE) or favorable (LSE) segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for handling multi-time segment data\n",
    "def merge_segments(dict):\n",
    "    \"\"\"Finds segments of similar solar exposure class\"\"\"\n",
    "    segdata = None\n",
    "\n",
    "    for gdf in dict.values():\n",
    "        if segdata is None:\n",
    "            segdata = gdf\n",
    "        else:\n",
    "            segdata = gpd.overlay(segdata, gdf, how='intersection')\n",
    "            segdata = segdata.loc[:, ~segdata.columns.str.endswith('_1')]\n",
    "            segdata = segdata.loc[:, ~segdata.columns.str.endswith('_2')]\n",
    "\n",
    "    return segdata.reset_index(drop=True)\n",
    "\n",
    "def merge_rest(dict):\n",
    "    \"\"\"Merges the remaining segments\"\"\"\n",
    "    return pd.concat(dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSE segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def process_hse(tod_list, start, end=None):\n",
    "    hse_dict = {}\n",
    "    rest_dict = {}\n",
    "\n",
    "    for tod in islice(tod_list, start, end):\n",
    "        hse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_not_avoided.feather')\n",
    "        hse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_detours.feather')\n",
    "        hse_dict[f'{tod}_hse'] = hse_not_avoided.append(hse_detours)\n",
    "\n",
    "        mse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_not_avoided.feather')\n",
    "        mse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_detours.feather')    \n",
    "        lse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_lse_not_avoided.feather')\n",
    "        lse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_lse_detours.feather')\n",
    "        avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_avoided.feather')\n",
    "        rest_dict[f'{tod}_rest'] = avoided.append(lse_not_avoided).append(lse_detours).append(mse_not_avoided).append(mse_detours)\n",
    "    \n",
    "    hse = merge_segments(hse_dict)\n",
    "    rest = merge_segments(rest_dict)\n",
    "\n",
    "    hse_critical = hse.overlay(rest, how='difference')\n",
    "    \n",
    "    if end is None:\n",
    "        outname = f'hse_critical'\n",
    "    else:\n",
    "        outname = f'hse_critical_{tod_list[start]}-{tod_list[end-1]}'\n",
    "    hse_critical.to_feather(out_segment_level / f'{outname}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSE segments for all times of day\n",
    "process_hse(tod_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HSE segments for 1 PM and 4 PM\n",
    "process_hse(tod_list, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSE segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def process_lse(tod_list, start, end=None):\n",
    "    lse_dict = {}\n",
    "    rest_dict = {}\n",
    "\n",
    "    for tod in islice(tod_list, start, end):\n",
    "        lse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_lse_not_avoided.feather')\n",
    "        lse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_lse_detours.feather')\n",
    "        lse_dict[f'{tod}'] = lse_not_avoided.append(lse_detours)\n",
    "\n",
    "        avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_avoided.feather')\n",
    "        hse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_not_avoided.feather')\n",
    "        hse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_detours.feather')\n",
    "        mse_not_avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_not_avoided.feather')\n",
    "        mse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_detours.feather')   \n",
    "        rest_dict[f'{tod}'] = avoided.append(hse_not_avoided).append(hse_detours).append(mse_not_avoided).append(mse_detours)\n",
    "    \n",
    "    lse = merge_segments(lse_dict)\n",
    "    rest = merge_segments(rest_dict)\n",
    "\n",
    "    lse_favorable = lse.overlay(rest, how='difference')\n",
    "    \n",
    "    if end is None:\n",
    "        outname = f'lse_favorable'\n",
    "    else:\n",
    "        outname = f'lse_favorable_{tod_list[start]}-{tod_list[end-1]}'\n",
    "    lse_favorable.to_feather(out_segment_level / f'{outname}.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSE segments for all times of day\n",
    "process_lse(tod_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSE segments for 1 PM and 4 PM\n",
    "process_lse(tod_list, 1, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heal-routing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
