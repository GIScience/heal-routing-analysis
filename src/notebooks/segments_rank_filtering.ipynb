{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment filtering and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ignore FutureWarnings from geopandas\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', message='.*initial implementation of Parquet.*')\n",
    "# Ignore SettingWithCopyWarning from (geo-)pandas\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# Config\n",
    "tod_list = ['10am', '1pm', '4pm', '7pm']\n",
    "\n",
    "day = 170\n",
    "sensitivity_factor = 0.8\n",
    "\n",
    "in_dir = Path(f'../../export/{day}/{sensitivity_factor}/exportdata/aggregation')\n",
    "out_dir = in_dir.parent.parent / 'analysis'\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "out_segment_level = out_dir / 'segment_level'\n",
    "out_segment_level.mkdir(exist_ok=True)\n",
    "\n",
    "default_type = 'shortest'\n",
    "count_threshold = 0.01\n",
    "\n",
    "high_sol_expo = 90\n",
    "low_sol_expo = 50\n",
    "\n",
    "crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def subfolder(out_dir, time_of_day):\n",
    "    \"\"\"Returns the respective folder path and creates subfolders in out_dir with timestamps if not existent already\"\"\"\n",
    "    out_folder = out_dir / f'{time_of_day}'\n",
    "    out_folder.mkdir(exist_ok=True)\n",
    "    return out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters to extract segments ranks \n",
    "class EqualSegmentRanking:\n",
    "    \"\"\"Filters for equal segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, time_of_day):\n",
    "        self.data = data.to_crs(crs)\n",
    "        self.time_of_day = time_of_day\n",
    "\n",
    "    @property\n",
    "    def cool_corridors(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_unavoidables(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, {high_sol_expo} % >= solar exposure']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_unavoidables(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'equal, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "class DetourSegmentRanking:\n",
    "    \"\"\"Filters for detour segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, time_of_day):\n",
    "        self.data = data.to_crs(crs)\n",
    "        self.time_of_day = time_of_day\n",
    "\n",
    "    @property\n",
    "    def cool_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, {high_sol_expo} % >= solar exposure']\n",
    "            \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_detours(self):\n",
    "        filtered = self.data[self.data[f'ranking_{self.time_of_day}'] == f'detour, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "            \n",
    "        return filtered\n",
    "    \n",
    "class DefaultSegmentRanking:\n",
    "    \"\"\"Filters the default segment data sets\"\"\"\n",
    "\n",
    "    def __init__(self, data, equal_segments, time_of_day):\n",
    "        self.time_of_day = time_of_day\n",
    "        # Avoided default segments\n",
    "        self.difference = gpd.overlay(data, equal_segments, how='difference')\n",
    "\n",
    "    @property\n",
    "    def lse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, solar exposure < {low_sol_expo} %']\n",
    "        \n",
    "        return filtered\n",
    "\n",
    "    @property\n",
    "    def hse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, {high_sol_expo} % >= solar exposure']\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    @property\n",
    "    def mse_defaults(self):\n",
    "        filtered = self.difference[self.difference[f'ranking_{self.time_of_day}'] == f'{default_type}, {low_sol_expo} % <= solar exposure < {high_sol_expo} %']\n",
    "        \n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter segment data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_file = gpd.read_feather(in_dir / f'counts_{default_type}_alltimes.feather')\n",
    "default_file.to_crs(crs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10am...\n",
      "...equals...\n",
      "...detours...\n",
      "...avoided segments...\n",
      "Processing 1pm...\n",
      "...equals...\n",
      "...detours...\n",
      "...avoided segments...\n",
      "Processing 4pm...\n",
      "...equals...\n",
      "...detours...\n",
      "...avoided segments...\n",
      "Processing 7pm...\n",
      "...equals...\n",
      "...detours...\n",
      "...avoided segments...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for time_of_day in tod_list:\n",
    "    print(f'Processing {time_of_day}...')\n",
    "    print(f'...equals...')\n",
    "    equal_segments = EqualSegmentRanking(gpd.read_feather(in_dir / f'counts_{time_of_day}_equal.feather'), time_of_day)\n",
    "\n",
    "    # Equal + low solar exposure\n",
    "    lse_equals = equal_segments.cool_corridors\n",
    "    lse_equals.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_cool_corridors.feather')\n",
    "\n",
    "    # Equal + high solar exposure\n",
    "    hse_unavoidables = equal_segments.hse_unavoidables\n",
    "    hse_unavoidables.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_unavoidables.feather')\n",
    "    \n",
    "    # Equal + medium solar exposure\n",
    "    mse_unavoidables = equal_segments.mse_unavoidables\n",
    "    mse_unavoidables.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_unavoidables.feather')\n",
    "\n",
    "    print(f'...detours...')\n",
    "    detour_segments = DetourSegmentRanking(gpd.read_feather(in_dir / f'counts_{time_of_day}_detour.feather'), time_of_day)\n",
    "\n",
    "    # Detour + low solar exposure\n",
    "    lse_detours = detour_segments.cool_detours\n",
    "    lse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_cool_detours.feather')\n",
    "\n",
    "    # Detour + high solar exposure\n",
    "    hse_detours = detour_segments.hse_detours\n",
    "    hse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_detours.feather')\n",
    "\n",
    "    # Detour + medium solar exposure\n",
    "    mse_detours = detour_segments.mse_detours\n",
    "    mse_detours.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_detours.feather')\n",
    "    \n",
    "    print(f'...avoided segments...')\n",
    "    default_segments = DefaultSegmentRanking(default_file, equal_segments.data, time_of_day)\n",
    "\n",
    "    # Avoided + low solar exposure\n",
    "    lse_avoided = default_segments.lse_defaults\n",
    "    lse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_lse_avoided.feather')\n",
    "    # Avoided + high solar exposure\n",
    "    hse_avoided = default_segments.hse_defaults\n",
    "    hse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_hse_avoided.feather')\n",
    "    # Avoided + medium solar exposure\n",
    "    mse_avoided = default_segments.mse_defaults\n",
    "    mse_avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_mse_avoided.feather')\n",
    "\n",
    "    avoided = pd.concat([lse_avoided, hse_avoided, mse_avoided], ignore_index=True)\n",
    "    avoided.to_feather(subfolder(out_segment_level, time_of_day) / f'{time_of_day}_avoided.feather')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find hot segments where action is needed\n",
    "\n",
    "To change what tods should be included, slice tod_list in the for loop and rename the resulting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hse_dict = {}\n",
    "mse_dict = {}\n",
    "rest_dict = {}\n",
    "\n",
    "for tod in tod_list[1:3]:\n",
    "    hse_unavoidables = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_unavoidables.feather')\n",
    "    hse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_detours.feather')\n",
    "    hse_dict[f'{tod}_hse'] = hse_unavoidables.append(hse_detours)\n",
    "\n",
    "    mse_unavoidables = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_unavoidables.feather')\n",
    "    mse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_detours.feather')    \n",
    "    lse_equals = gpd.read_feather(out_segment_level / tod / f'{tod}_cool_corridors.feather')\n",
    "    lse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_cool_detours.feather')\n",
    "    avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_avoided.feather')\n",
    "    rest_dict[f'{tod}_rest'] = lse_equals.append(lse_detours).append(avoided).append(mse_unavoidables).append(mse_detours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1610768/4090679614.py:7: UserWarning: `keep_geom_type=True` in overlay resulted in 297 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  hse = gpd.overlay(hse, gdf, how='intersection')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hse = None\n",
    "\n",
    "for gdf in hse_dict.values():\n",
    "    if hse is None:\n",
    "        hse = gdf\n",
    "    else:\n",
    "        hse = gpd.overlay(hse, gdf, how='intersection')\n",
    "        hse = hse.loc[:, ~hse.columns.str.endswith('_1')]\n",
    "        hse = hse.loc[:, ~hse.columns.str.endswith('_2')]\n",
    "\n",
    "hse = hse.reset_index(drop=True)\n",
    "    \n",
    "len(hse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12124"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest = pd.concat(rest_dict.values())\n",
    "len(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hse_action = hse.overlay(rest, how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hse_action.to_feather(out_seg_filter_rank / 'hse_action.feather')\n",
    "hse_action.to_feather(out_segment_level / 'hse_action_1-4.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find cool corridors where no action is needed and which can be used as showcase/best practice\n",
    "\n",
    "To change what tods should be included, slice tod_list in the for loop and rename the resulting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lse_dict = {}\n",
    "rest_dict = {}\n",
    "\n",
    "for tod in tod_list[1:3]:\n",
    "    lse_equals = gpd.read_feather(out_segment_level / tod / f'{tod}_cool_corridors.feather')\n",
    "    lse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_cool_detours.feather')\n",
    "    lse_dict[f'{tod}'] = lse_equals.append(lse_detours)\n",
    "\n",
    "    avoided = gpd.read_feather(out_segment_level / tod / f'{tod}_avoided.feather')\n",
    "    hse_unavoidables = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_unavoidables.feather')\n",
    "    hse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_hse_detours.feather')\n",
    "    mse_unavoidables = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_unavoidables.feather')\n",
    "    mse_detours = gpd.read_feather(out_segment_level / tod / f'{tod}_mse_detours.feather')   \n",
    "    rest_dict[f'{tod}'] = avoided.append(hse_unavoidables).append(hse_detours).append(mse_unavoidables).append(mse_detours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1610768/3569870631.py:7: UserWarning: `keep_geom_type=True` in overlay resulted in 2955 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  lse = gpd.overlay(lse, gdf, how='intersection')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1470"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lse = None\n",
    "\n",
    "for gdf in lse_dict.values():\n",
    "    if lse is None:\n",
    "        lse = gdf\n",
    "    else:\n",
    "        lse = gpd.overlay(lse, gdf, how='intersection')\n",
    "        lse = lse.loc[:, ~lse.columns.str.endswith('_1')]\n",
    "        lse = lse.loc[:, ~lse.columns.str.endswith('_2')]\n",
    "\n",
    "lse = lse.reset_index(drop=True)\n",
    "    \n",
    "len(lse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8790"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest = pd.concat(rest_dict.values())\n",
    "len(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_corridors = lse.overlay(rest, how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cool_corridors.to_feather(out_seg_filter_rank / 'cool_corridors.feather')\n",
    "cool_corridors.to_feather(out_segment_level / 'cool_corridors_1-4.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heal-routing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
